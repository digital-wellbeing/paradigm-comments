
@article{anvariUsingAnchorbasedMethods2021,
  title = {Using Anchor-Based Methods to Determine the Smallest Effect Size of Interest},
  author = {Anvari, Farid and Lakens, Dani{\"e}l},
  year = {2021},
  month = sep,
  journal = {Journal of Experimental Social Psychology},
  volume = {96},
  pages = {104159},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2021.104159},
  abstract = {Effect sizes are an important outcome of quantitative research, but few guidelines exist that explain how researchers can determine which effect sizes are meaningful. Psychologists often want to study effects that are large enough to make a difference to people's subjective experience. Thus, subjective experience is one way to gauge the meaningfulness of an effect. We propose and illustrate one method for how to quantify the smallest subjectively experienced difference\textemdash the smallest change in an outcome measure that individuals consider to be meaningful enough in their subjective experience such that they are willing to rate themselves as feeling different\textemdash using an anchor-based method with a global rating of change question applied to the positive and negative affect scale. We provide a step-by-step guide for the questions that researchers need to consider in deciding whether and how to use the anchor-based method, and we make explicit the assumptions of the method that future research can examine. For researchers interested in people's subjective experiences, this anchor-based method provides one way to specify a smallest effect size of interest, which allows researchers to interpret observed results in terms of their theoretical and practical significance.},
  langid = {english},
  keywords = {Minimum important difference,Negative affect,Positive affect,Practical significance,Smallest effect size of interest,Smallest subjectively experienced difference,Subjectively experienced difference}
}

@article{appelAreSocialMedia2020,
  title = {Are {{Social Media Ruining Our Lives}}? {{A Review}} of {{Meta-Analytic Evidence}}},
  shorttitle = {Are {{Social Media Ruining Our Lives}}?},
  author = {Appel, Markus and Marker, Caroline and Gnambs, Timo},
  year = {2020},
  month = mar,
  journal = {Review of General Psychology},
  volume = {24},
  number = {1},
  pages = {60--74},
  issn = {1089-2680, 1939-1552},
  doi = {10.1177/1089268019880891},
  abstract = {A growing number of studies have examined the psychological corollaries of using social networking sites (SNSs) such as Facebook, Instagram, or Twitter (often called social media). The interdisciplinary research area and conflicting evidence from primary studies complicate the assessment of current scholarly knowledge in this field of high public attention. We review meta-analytic evidence on three hotly debated topics regarding the effects of SNSs: well-being, academic achievement, and narcissism. Meta-analyses from different laboratories draw a rather equivocal picture. They show small associations in the r = .10 range between the intensity of SNS use and loneliness, self-esteem, life satisfaction, or selfreported depression, and somewhat stronger links to a thin body ideal and higher social capital. There is no indication for potential devastating effects of social media on school achievement; social media use and school grades are unrelated for adolescents. The meta-analyses revealed small to moderate associations between narcissism and SNS use. In sum, metaanalytic evidence is not in support of dramatic claims relating social media use to mischief.},
  langid = {english}
}

@article{baguleyStandardizedSimpleEffect2009,
  title = {Standardized or Simple Effect Size: {{What}} Should Be Reported?},
  shorttitle = {Standardized or Simple Effect Size},
  author = {Baguley, Thom},
  year = {2009},
  journal = {British Journal of Psychology},
  volume = {100},
  number = {3},
  pages = {603--617},
  issn = {2044-8295},
  doi = {10.1348/000712608X377117},
  abstract = {It is regarded as best practice for psychologists to report effect size when disseminating quantitative research findings. Reporting of effect size in the psychological literature is patchy \textendash{} though this may be changing \textendash{} and when reported it is far from clear that appropriate effect size statistics are employed. This paper considers the practice of reporting point estimates of standardized effect size and explores factors such as reliability, range restriction and differences in design that distort standardized effect size unless suitable corrections are employed. For most purposes simple (unstandardized) effect size is more robust and versatile than standardized effect size. Guidelines for deciding what effect size metric to use and how to report it are outlined. Foremost among these are: (i) a preference for simple effect size over standardized effect size, and (ii) the use of confidence intervals to indicate a plausible range of values the effect might take. Deciding on the appropriate effect size statistic to report always requires careful thought and should be influenced by the goals of the researcher, the context of the research and the potential needs of readers.},
  copyright = {2009 The British Psychological Society},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1348/000712608X377117}
}

@article{bestOnlineCommunicationSocial2014,
  title = {Online Communication, Social Media and Adolescent Wellbeing: {{A}} Systematic Narrative Review},
  shorttitle = {Online Communication, Social Media and Adolescent Wellbeing},
  author = {Best, Paul and Manktelow, Roger and Taylor, Brian},
  year = {2014},
  month = jun,
  journal = {Children and Youth Services Review},
  volume = {41},
  pages = {27--36},
  issn = {01907409},
  doi = {10.1016/j.childyouth.2014.03.001},
  abstract = {Background: Much debate and polarisation exist regarding the impact of online social technologies on the mental wellbeing of young people. Objective: To systematically review and synthesise current empirical research on this topic, identifying both the beneficial and harmful effects of online communication and social media technology amongst young people. Methods: A systematic narrative review of research published between January 2003 and April 2013, retrieved using rigorous searching on eight bibliographic databases. Results were then subject to review using a quality appraisal tool and a narrative synthesis methodology. A theoretical framework was developed for the synthesis using concepts from mental health and communication studies literature. Results: Systematic searching retrieved 43 original research papers investigating or exploring the effects of online technologies on adolescent mental well-being or related concept(s). The benefits of using online technologies were reported as increased self-esteem, perceived social support, increased social capital, safe identity experimentation and increased opportunity for self-disclosure. Harmful effects were reported as increased exposure to harm, social isolation, depression and cyber-bullying. The majority of studies reported either mixed or no effect(s) of online social technologies on adolescent wellbeing. Conclusions: This systematic narrative review has revealed contradictory evidence while revealing an absence of robust causal research regarding the impact of social media on mental wellbeing of young people. Online technologies are increasingly being used for health and social care purposes, but further research is required to give confidence that these are appropriately designed to promote the mental health care and support of young people.},
  langid = {english}
}

@article{Beyens2021,
  title = {Data Set Belonging to {{Beyens}} et al. (2020). {{The}} Effect of Social Media on Well-Being Differs from Adolescent to Adolescent},
  author = {Beyens, I. and Pouwels, J.L. and {van Driel}, I.I. and Keijsers, Loes and Valkenburg, P.M.},
  year = {2021},
  month = jan,
  doi = {10.21942/uva.12497990.v2}
}

@article{beyensEffectSocialMedia2020,
  title = {The Effect of Social Media on Well-Being Differs from Adolescent to Adolescent},
  author = {Beyens, Ine and Pouwels, J. Loes and {van Driel}, Irene I. and Keijsers, Loes and Valkenburg, Patti M.},
  year = {2020},
  month = jul,
  journal = {Scientific Reports},
  volume = {10},
  number = {1},
  pages = {10763},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-67727-7},
  abstract = {The question whether social media use benefits or undermines adolescents' well-being is an important societal concern. Previous empirical studies have mostly established across-the-board effects among (sub)populations of adolescents. As a result, it is still an open question whether the effects are unique for each individual adolescent. We sampled adolescents' experiences six times per day for one week to quantify differences in their susceptibility to the effects of social media on their momentary affective well-being. Rigorous analyses of 2,155 real-time assessments showed that the association between social media use and affective well-being differs strongly across adolescents: While 44\% did not feel better or worse after passive social media use, 46\% felt better, and 10\% felt worse. Our results imply that person-specific effects can no longer be ignored in research, as well as in prevention and intervention programs.},
  copyright = {2020 The Author(s)},
  langid = {english}
}

@article{beyensSocialMediaUse2021,
  title = {Social {{Media Use}} and {{Adolescents}}' {{Well-Being}}: {{Developing}} a {{Typology}} of {{Person-Specific Effect Patterns}}},
  shorttitle = {Social {{Media Use}} and {{Adolescents}}' {{Well-Being}}},
  author = {Beyens, Ine and Pouwels, J. Loes and {van Driel}, Irene I. and Keijsers, Loes and Valkenburg, Patti M.},
  year = {2021},
  month = dec,
  journal = {Communication Research},
  pages = {00936502211038196},
  publisher = {{SAGE Publications Inc}},
  issn = {0093-6502},
  doi = {10.1177/00936502211038196},
  abstract = {This study investigated the effects of active private, passive private, and passive public social media use on adolescents' affective well-being. Intensive longitudinal data (34,930 assessments in total) were collected through a preregistered three-week experience sampling method study among 387 adolescents. N\,=\,1 time series were investigated, using Dynamic Structural Equation Modeling. Findings showed that different types of social media use very rarely yielded different effects within one and the same adolescent: 45\% of adolescents experienced no changes in well-being due to any of the three types of social media use, 28\% only experienced declines in well-being, and 26\% only experienced increases in well-being. Only one adolescent experienced the theoretically expected effect pattern of a positive effect of active private and passive private use and negative effect of passive public use. Together, the findings suggest that the active\textendash passive use dichotomy in social media research is less clear-cut than it might seem.},
  langid = {english},
  keywords = {DSEM,experience sampling,idiographic approach,social media,well-being}
}

@article{bolgerCausalProcessesPsychology2019,
  ids = {bolgerCausalProcessesPsychology},
  title = {Causal Processes in Psychology Are Heterogeneous.},
  author = {Bolger, Niall and Zee, Katherine S. and {Rossignac-Milon}, Maya and Hassin, Ran R.},
  year = {2019},
  month = apr,
  journal = {Journal of Experimental Psychology: General},
  volume = {148},
  number = {4},
  pages = {601--618},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/xge0000558},
  abstract = {All experimenters know that human and animal subjects do not respond uniformly to experimental treatments. Yet theories and findings in experimental psychology either ignore this causal effect heterogeneity or treat it as uninteresting error. This is the case even when data are available to examine effect heterogeneity directly, in within-subjects designs where experimental effects can be examined subject by subject. Using data from four repeated-measures experiments, we show that effect heterogeneity can be modeled readily, that its discovery presents exciting opportunities for theory and methods, and that allowing for it in study designs is good research practice. This evidence suggests that experimenters should work from the assumption that causal effects are heterogeneous. Such a working assumption will be of particular benefit, given the increasing diversity of subject populations in psychology.},
  langid = {english}
}

@article{cohenProblemUnitsCircumstance1999,
  title = {The {{Problem}} of {{Units}} and the {{Circumstance}} for {{POMP}}},
  author = {Cohen, Patricia and Cohen, Jacob and Aiken, Leona S. and West, Stephen G.},
  year = {1999},
  month = jul,
  journal = {Multivariate Behavioral Research},
  volume = {34},
  number = {3},
  pages = {315--346},
  publisher = {{Routledge}},
  issn = {0027-3171},
  doi = {10.1207/S15327906MBR3403_2},
  abstract = {Many areas of the behavioral sciences have few measures that are accepted as the standard for the operationalization of a construct. One consequence is that there is hardly ever an articulated and understood framework for the units of the measures that are employed. Without meaningful measurement units, theoretical formulations are limited to statements of the direction of an effect or association, or to effects expressed in standardized units. Thus the long term scientific goal of generation of laws expressing the relationships among variables in scale units is greatly hindered. This article reviews alternative methods of scoring a scale. Two recent journal volumes are surveyed with regard to current scoring practices. Alternative methods of scoring are evaluated against seven articulated criteria representing the information conveyed by each in an illustrative example. Converting scores to the percent of maximum possible score (POMP) is shown to provide useful additional information in many cases.},
  annotation = {\_eprint: https://doi.org/10.1207/S15327906MBR3403\_2}
}

@article{dickson2018screen,
  title = {Screen-Based Activities and Children and Young People's Mental Health and Psychosocial Wellbeing: A Systematic Map of Reviews},
  author = {Dickson, Kelly and Richardson, Michelle and Kwan, Irene and MacDowall, Wendy and Burchett, Helen and Stansfield, Claire and Brunton, Ginny and Sutcliffe, Katy and Thomas, James},
  year = {2019},
  publisher = {{EPPI-Centre, UCL Institute of Education, University College London}}
}

@book{gelmanBayesianDataAnalysis2013,
  title = {Bayesian {{Data Analysis}}, {{Third Edition}}},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  year = {2013},
  month = nov,
  publisher = {{Chapman and Hall/CRC}},
  address = {{Boca Raton}},
  abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors\textemdash all leaders in the statistics community\textemdash introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition   Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code   The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book's web page.},
  isbn = {978-1-4398-4095-5},
  langid = {english},
  lccn = {S8},
  keywords = {bayesian statistics,Computers / Mathematical \& Statistical Software,Mathematics / Probability \& Statistics / General,Psychology / Research \& Methodology,Statistics},
  annotation = {00000}
}

@book{gelmanDataAnalysisUsing2007,
  title = {Data {{Analysis Using Regression}} and {{Multilevel}}/{{Hierarchical Models}}},
  author = {Gelman, Andrew and Hill, Jennifer},
  year = {2007},
  publisher = {{Cambridge University Press}},
  address = {{New York, NY}},
  abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout. Author resource page: http://www.stat.columbia.edu/\textasciitilde gelman/arm/},
  isbn = {978-0-521-68689-1},
  langid = {english},
  lccn = {S5},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Regression Analysis,Political Science / General,Psychology / Assessment; Testing \& Measurement,Statistics},
  annotation = {00058}
}

@article{groszTabooExplicitCausal2020,
  title = {The {{Taboo Against Explicit Causal Inference}} in {{Nonexperimental Psychology}}},
  author = {Grosz, Michael P. and Rohrer, Julia M. and Thoemmes, Felix},
  year = {2020},
  month = sep,
  journal = {Perspectives on Psychological Science},
  volume = {15},
  number = {5},
  pages = {1243--1255},
  publisher = {{SAGE Publications Inc}},
  issn = {1745-6916},
  doi = {10.1177/1745691620921521},
  abstract = {Causal inference is a central goal of research. However, most psychologists refrain from explicitly addressing causal research questions and avoid drawing causal inference on the basis of nonexperimental evidence. We argue that this taboo against causal inference in nonexperimental psychology impairs study design and data analysis, holds back cumulative research, leads to a disconnect between original findings and how they are interpreted in subsequent work, and limits the relevance of nonexperimental psychology for policymaking. At the same time, the taboo does not prevent researchers from interpreting findings as causal effects\textemdash the inference is simply made implicitly, and assumptions remain unarticulated. Thus, we recommend that nonexperimental psychologists begin to talk openly about causal assumptions and causal effects. Only then can researchers take advantage of recent methodological advances in causal reasoning and analysis and develop a solid understanding of the underlying causal mechanisms that can inform future research, theory, and policymakers.},
  langid = {english},
  keywords = {causal inference,instrumental-variable estimation,nonexperimental,observational studies}
}

@article{hernanCWordScientificEuphemisms2018,
  title = {The {{C-Word}}: {{Scientific Euphemisms Do Not Improve Causal Inference From Observational Data}}},
  shorttitle = {The {{C-Word}}},
  author = {Hern{\'a}n, Miguel A.},
  year = {2018},
  month = may,
  journal = {American Journal of Public Health},
  volume = {108},
  number = {5},
  pages = {616--619},
  issn = {0090-0036, 1541-0048},
  doi = {10.2105/AJPH.2018.304337},
  langid = {english}
}

@article{howardVariableCenteredPersonCenteredPersonSpecific2018,
  title = {Variable-{{Centered}}, {{Person-Centered}}, and {{Person-Specific Approaches}}: {{Where Theory Meets}} the {{Method}}},
  shorttitle = {Variable-{{Centered}}, {{Person-Centered}}, and {{Person-Specific Approaches}}},
  author = {Howard, Matt C. and Hoffman, Michael E.},
  year = {2018},
  month = oct,
  journal = {Organizational Research Methods},
  volume = {21},
  number = {4},
  pages = {846--876},
  issn = {1094-4281, 1552-7425},
  doi = {10.1177/1094428117744021},
  abstract = {The variable-centered approach is favored in management and applied psychology, but the personcentered approach is quickly growing in popularity. A partial cause for this rise is the finer-grained detail that it allows. Many researchers may be unaware, however, that another approach may provide even finer-grained detail: the person-specific approach. In the current article, we (a) detail the purpose of each approach, (b) describe how to determine when each approach is most appropriate, and (c) delineate when the approaches diverge to give differing results. Through achieving these goals, we suggest that no single approach is the ``best.'' Instead, the choice of approach should be guided by the research question. To further emphasize this point, we provide illustrative examples using real data to answer three distinct research questions. The results show that each research question can be fully addressed only by the appropriate approach. To conclude, we directly suggest certain research areas that may benefit from the application of person-centered and person-specific approaches. Together, we believe that discussing variable-centered, person-centered, and person-specific approaches together may provide a more thorough understanding of each.},
  langid = {english}
}

@article{ijzermanUseCautionWhen2020,
  title = {Use Caution When Applying Behavioural Science to Policy},
  author = {IJzerman, Hans and Lewis, Neil A. and Przybylski, Andrew K. and Weinstein, Netta and DeBruine, Lisa and Ritchie, Stuart J. and Vazire, Simine and Forscher, Patrick S. and Morey, Richard D. and Ivory, James D. and Anvari, Farid},
  year = {2020},
  month = nov,
  journal = {Nature Human Behaviour},
  volume = {4},
  number = {11},
  pages = {1092--1094},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-020-00990-w},
  abstract = {Social and behavioural scientists have attempted to speak to the COVID-19 crisis. But is behavioural research on COVID-19 suitable for making policy decisions? We offer a taxonomy that lets our science advance in `evidence readiness levels' to be suitable for policy. We caution practitioners to take extreme care translating our findings to applications.},
  copyright = {2020 Springer Nature Limited},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Comments \& Opinion Subject\_term: Human behaviour;Psychology Subject\_term\_id: human-behaviour;psychology}
}

@article{jensenYoungAdolescentsDigital2019,
  title = {Young {{Adolescents}}' {{Digital Technology Use}} and {{Mental Health Symptoms}}: {{Little Evidence}} of {{Longitudinal}} or {{Daily Linkages}}},
  shorttitle = {Young {{Adolescents}}' {{Digital Technology Use}} and {{Mental Health Symptoms}}},
  author = {Jensen, Michaeline and George, Madeleine J. and Russell, Michael R. and Odgers, Candice L.},
  year = {2019},
  month = nov,
  journal = {Clinical Psychological Science},
  volume = {7},
  number = {6},
  pages = {1416--1433},
  issn = {2167-7026, 2167-7034},
  doi = {10.1177/2167702619859336},
  abstract = {This study examines whether 388 adolescents' digital technology use is associated with mental-health symptoms during early adolescence to midadolescence. Adolescents completed an initial Time 1 (T1) assessment in 2015, followed by a 14-day ecological momentary assessment (EMA) via mobile phone in 2016\textendash 2017 that yielded 13,017 total observations over 5,270 study days. Adolescents' T1 technology use did not predict later mental-health symptoms. Adolescents' reported mental health was also not worse on days when they reported spending more versus less time on technology. Little was found to support daily quadratic associations (whereby adolescent mental health was worse on days with little or excessive use). Adolescents at higher risk for mental-health problems also exhibited no signs of increased risk for mental-health problems on higher technology use days. Findings from this EMA study do not support the narrative that young adolescents' digital technology usage is associated with elevated mental-health symptoms.},
  langid = {english}
}

@misc{johannesHowShouldWe2021a,
  title = {How Should We Investigate Variation in the Relation between Social Media and Well-Being?},
  author = {Johannes, Niklas and Masur, Philipp K. and Vuorre, Matti and Przybylski, Andrew K.},
  year = {2021},
  month = oct,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/xahbg},
  abstract = {Most researchers studying the relation between social media use and well-being find small to no associations, yet policymakers and public stakeholders keep asking for more evidence. One way the field is reacting is by inspecting the variation around average relations\textemdash with the goal of describing individual social media users. Here, we argue that this approach produces findings that are not as informative as they could be. Our analysis begins by describing how the field got to this point. Then, we explain the problems with the current approach of studying variation and how it loses sight of one of the most important goals of a quantitative social science: generalizing from a sample to a population. We propose a principled approach to quantify, interpret, and explain variation in average relations by: (1) conducting model comparisons, (2) defining a region of practical equivalence and testing the theoretical distribution of relations against that region, (3) defining a smallest effect size of interest and comparing it against the theoretical distribution. We close with recommendations to either study moderators as systematic factors that explain variation or to commit to a person-specific approach and conduct N = 1 studies and qualitative research.},
  langid = {american},
  keywords = {effect heterogeneity,Social and Behavioral Sciences,social media,well-being}
}

@article{kruschkeBayesianAssessmentNull2011,
  title = {Bayesian {{Assessment}} of {{Null Values Via Parameter Estimation}} and {{Model Comparison}}},
  author = {Kruschke, John K.},
  year = {2011},
  month = may,
  journal = {Perspectives on Psychological Science},
  volume = {6},
  number = {3},
  pages = {299--312},
  issn = {1745-6916, 1745-6924},
  doi = {10.1177/1745691611406925},
  abstract = {Psychologists have been trained to do data analysis by asking whether null values can be rejected. Is the difference between groups nonzero? Is choice accuracy not at chance level? These questions have been traditionally addressed by null hypothesis significance testing (NHST). NHST has deep problems that are solved by Bayesian data analysis. As psychologists transition to Bayesian data analysis, it is natural to ask how Bayesian analysis assesses null values. The article explains and evaluates two different Bayesian approaches. One method involves Bayesian model comparison (and uses Bayes factors). The second method involves Bayesian parameter estimation and assesses whether the null value falls among the most credible values. Which method to use depends on the specific question that the analyst wants to answer, but typically the estimation approach (not using Bayes factors) provides richer information than the model comparison approach.},
  langid = {english},
  pmid = {26168520},
  keywords = {Bayes,model comparison,parameter estimation,Statistics},
  annotation = {00112}
}

@article{kruschkeBayesianNewStatistics2017,
  title = {The {{Bayesian New Statistics}}: {{Hypothesis}} Testing, Estimation, Meta-Analysis, and Power Analysis from a {{Bayesian}} Perspective},
  shorttitle = {The {{Bayesian New Statistics}}},
  author = {Kruschke, John K. and Liddell, Torrin M.},
  year = {2017},
  month = feb,
  journal = {Psychonomic Bulletin \& Review},
  pages = {1--29},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-016-1221-4},
  abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed ``the New Statistics'' (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
  langid = {english},
  keywords = {Statistics},
  annotation = {00000}
}

@article{moellerWordStandardizationLongitudinal2015,
  title = {A Word on Standardization in Longitudinal Studies: Don't},
  shorttitle = {A Word on Standardization in Longitudinal Studies},
  author = {Moeller, Julia},
  year = {2015},
  journal = {Frontiers in Psychology},
  volume = {6},
  issn = {1664-1078}
}

@article{molenaarManifestoPsychologyIdiographic2004,
  title = {A {{Manifesto}} on {{Psychology}} as {{Idiographic Science}}: {{Bringing}} the {{Person Back Into Scientific Psychology}}, {{This Time Forever}}},
  shorttitle = {A {{Manifesto}} on {{Psychology}} as {{Idiographic Science}}},
  author = {Molenaar, Peter C. M.},
  year = {2004},
  month = oct,
  journal = {Measurement: Interdisciplinary Research and Perspectives},
  volume = {2},
  number = {4},
  pages = {201--218},
  publisher = {{Routledge}},
  issn = {1536-6367},
  doi = {10.1207/s15366359mea0204_1},
  abstract = {Psychology is focused on variation between cases (interindividual variation). Results thus obtained are considered to be generalizable to the understanding and explanation of variation within single cases (intraindividual variation). It is indicated, however, that the direct consequences of the classical ergodic theorems for psychology and psychometrics invalidate this conjectured generalizability: only under very strict conditions-which are hardly obtained in real psychological processes-can a generalization be made from a structure of interindividual variation to the analogous structure of intraindividual variation. Illustrations of the lack of this generalizability are given in the contexts of psychometrics, developmental psychology, and personality theory.},
  annotation = {\_eprint: https://doi.org/10.1207/s15366359mea0204\_1}
}

@article{molenaarNewPersonSpecificParadigm2009,
  title = {The {{New Person-Specific Paradigm}} in {{Psychology}}},
  author = {Molenaar, Peter C.M. and Campbell, Cynthia G.},
  year = {2009},
  month = apr,
  journal = {Current Directions in Psychological Science},
  volume = {18},
  number = {2},
  pages = {112--117},
  publisher = {{SAGE Publications Inc}},
  issn = {0963-7214},
  doi = {10.1111/j.1467-8721.2009.01619.x},
  abstract = {Most research methodology in the behavioral sciences employs interindividual analyses, which provide information about the state of affairs of the population. However, as shown by classical mathematical-statistical theorems (the ergodic theorems), such analyses do not provide information for, and cannot be applied at, the level of the individual, except on rare occasions when the processes of interest meet certain stringent conditions. When psychological processes violate these conditions, the interindividual analyses that are now standardly applied have to be replaced by analysis of intraindividual variation in order to obtain valid results. Two illustrations involving analysis of intraindividual variation of personality and emotional processes are given.},
  langid = {english},
  keywords = {Big Five Personality Factors,emotional experiences,ergodic conditions,interindividual variation,intraindividual variation,P-technique,R-technique}
}

@article{odgersAnnualResearchReview2020,
  title = {Annual {{Research Review}}: {{Adolescent}} Mental Health in the Digital Age: Facts, Fears, and Future Directions},
  shorttitle = {Annual {{Research Review}}},
  author = {Odgers, Candice L. and Jensen, Michaeline R.},
  year = {2020},
  month = mar,
  journal = {Journal of Child Psychology and Psychiatry},
  volume = {61},
  number = {3},
  pages = {336--348},
  issn = {0021-9630, 1469-7610},
  doi = {10.1111/jcpp.13190},
  langid = {english}
}

@article{ophirNewMediaScreenTime2020,
  title = {New-{{Media Screen Time Is Not}} ({{Necessarily}}) {{Linked}} to {{Depression}}: {{Comments}} on {{Twenge}}, {{Joiner}}, {{Rogers}}, and {{Martin}} (2018)},
  shorttitle = {New-{{Media Screen Time Is Not}} ({{Necessarily}}) {{Linked}} to {{Depression}}},
  author = {Ophir, Yaakov and {Lipshits-Braziler}, Yuliya and Rosenberg, Hananel},
  year = {2020},
  month = mar,
  journal = {Clinical Psychological Science},
  volume = {8},
  number = {2},
  pages = {374--378},
  issn = {2167-7026, 2167-7034},
  doi = {10.1177/2167702619849412},
  abstract = {In this commentary, we raise seven methodological concerns regarding Twenge, Joiner, Rogers, and Martin (2018), among which are inaccurate research measurements, negligible correlations between the main variables, insufficient and inadequate statistical analyses, and problematic interpretation of the results. In fact, the negligible associations between screen activities and depression, their decrease when demographic variables are controlled, and their fading away to nil among boys challenge the article's title and conclusions, according to which increases in depressive symptoms are attributed to increases in new-media screen use. This conclusion cannot be deduced from the reported results and could be misleading to the general public.},
  langid = {english}
}

@article{orbenAssociationAdolescentWellbeing2019,
  title = {The Association between Adolescent Well-Being and Digital Technology Use},
  author = {Orben, Amy and Przybylski, Andrew K.},
  year = {2019},
  month = feb,
  journal = {Nature Human Behaviour},
  volume = {3},
  number = {2},
  pages = {173--182},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-018-0506-1},
  abstract = {Adolescents regularly use digital technology, but its impact on their psychological well-being is unclear. Here, the authors examine three large datasets and find only a small negative association: digital technology use explains at most 0.4\% of well-being.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english}
}

@misc{valkenburgHowAssessVariation2022,
  title = {How to {{Assess Variation}} in the {{Association Between Social Media Use}} and {{Well-Being}}: {{A Reply}} to {{Johannes}}, {{Masur}}, {{Vuorre}}, \& {{Przybylski}} (2021)},
  shorttitle = {How to {{Assess Variation}} in the {{Association Between Social Media Use}} and {{Well-Being}}},
  author = {Valkenburg, Patti M. and Beyens, Ine and van Driel, Irene I. and Keijsers, Loes},
  year = {2022},
  month = apr,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/rwc73},
  abstract = {This paper is a reply to an unpublished critique by Johannes, Masur, Vuorre, \& Przybylski (2021) of our newly introduced approach to investigate the effects of social media use on well-being (Beyens et al., 2020; Valkenburg, Beyens, et al., 2021). Using experience sampling methodology (ESM) studies among sizeable samples of respondents, our unified approach combines the strengths of nomothetic methods of analysis (e.g., between-person regression models, moderation analyses), which are suited to understand group averages and generalize to populations, with idiographic methods of analysis (e.g., n = 1 time series analyses), which are suitable to assess changes within persons. Our unified approach challenges existing knowledge of media effects based on the nomothetic-only approach. As with many innovations, our unified approach has raised questions. In this paper, we disconfirm five criticisms on our work voiced in the preprint of Johannes et al. More importantly, we hope to answer questions of colleagues who are interested in replicating, extending, or building on our work.},
  langid = {american},
  keywords = {effects heteroneity,experience sampling methodology,idiographic approach,media effects,nomothetic approach,Quantitative Methods,Social and Behavioral Sciences,social media,Statistical Methods,Theory and Philosophy of Science}
}

@article{valkenburgSocialMediaBrowsing2021,
  title = {Social {{Media Browsing}} and {{Adolescent Well-Being}}: {{Challenging}} the ``{{Passive Social Media Use Hypothesis}}''},
  author = {Valkenburg, Patti M and Beyens, Ine and Pouwels, J Loes and {van Driel}, Irene I and Keijsers, Loes},
  year = {2021},
  pages = {19},
  langid = {english}
}

@article{valkenburgSocialMediaUse2021,
  title = {Social {{Media Use}} and {{Adolescents}}' {{Self-Esteem}}: {{Heading}} for a {{Person-Specific Media Effects Paradigm}}},
  shorttitle = {Social {{Media Use}} and {{Adolescents}}' {{Self-Esteem}}},
  author = {Valkenburg, Patti M. and Beyens, Ine and Pouwels, J Loes and {van Driel}, Irene I and Keijsers, Loes},
  year = {2021},
  month = feb,
  journal = {Journal of Communication},
  volume = {71},
  number = {1},
  pages = {56--78},
  issn = {0021-9916},
  doi = {10.1093/joc/jqaa039},
  abstract = {Eighteen earlier studies have investigated the associations between social media use (SMU) and adolescents' self-esteem, finding weak effects and inconsistent results. A viable hypothesis for these mixed findings is that the effect of SMU differs from adolescent to adolescent. To test this hypothesis, we conducted a preregistered three-week experience sampling study among 387 adolescents (13\textendash 15 years, 54\% girls). Each adolescent reported on his/her SMU and self-esteem six times per day (126 assessments per participant; 34,930 in total). Using a person-specific, N\,=\,1 method of analysis (Dynamic Structural Equation Modeling), we found that the majority of adolescents (88\%) experienced no or very small effects of SMU on self-esteem (-.10 \&lt; {$\beta$} \&lt; .10), whereas 4\% experienced positive (.10 {$\leq$} {$\beta$} {$\leq$} .17) and 8\% negative effects (-.21 {$\leq$} {$\beta$} {$\leq$} -.10). Our results suggest that person-specific effects can no longer be ignored in future media effects theories and research.}
}

@article{valkenburgSocialMediaUse2022,
  title = {Social Media Use and Its Impact on Adolescent Mental Health: {{An}} Umbrella Review of the Evidence},
  shorttitle = {Social Media Use and Its Impact on Adolescent Mental Health},
  author = {Valkenburg, Patti M. and Meier, Adrian and Beyens, Ine},
  year = {2022},
  month = apr,
  journal = {Current Opinion in Psychology},
  volume = {44},
  pages = {58--68},
  issn = {2352-250X},
  doi = {10.1016/j.copsyc.2021.08.017},
  abstract = {Literature reviews on how social media use affects adolescent mental health have accumulated at an unprecedented rate of late. Yet, a higher-level integration of the evidence is still lacking. We fill this gap with an up-to-date umbrella review, a review of reviews published between 2019 and mid-2021. Our search yielded 25 reviews: seven meta-analyses, nine systematic, and nine narrative reviews. Results showed that most reviews interpreted the associations between social media use and mental health as `weak' or `inconsistent,' whereas a few qualified the same associations as `substantial' and `deleterious.' We summarize the gaps identified in the reviews, provide an explanation for their diverging interpretations, and suggest several avenues for future research.},
  langid = {english},
  keywords = {Depression,Depressive symptoms,Facebook,Instagram,Meta-review,SNS,Social networking sites,Well-being}
}

@article{valkenburgSocialMediaUse2022a,
  title = {Social Media Use and Well-Being: {{What}} We Know and What We Need to Know},
  shorttitle = {Social Media Use and Well-Being},
  author = {Valkenburg, Patti M.},
  year = {2022},
  month = jun,
  journal = {Current Opinion in Psychology},
  volume = {45},
  pages = {101294},
  issn = {2352-250X},
  doi = {10.1016/j.copsyc.2021.12.006},
  abstract = {Research into the impact of social media use (SMU) on well-being (e.g., happiness) and ill-being (e.g., depression) has exploded over the past few years. From 2019 to August 2021, 27 reviews have been published: nine meta-analyses, nine systematic reviews, and nine narrative reviews, which together included hundreds of empirical studies. The aim of this umbrella review is to synthesize the results of these meta-analyses and reviews. Even though the meta-analyses are supposed to rely on the same evidence base, they yielded disagreeing associations with well- and ill-being, especially for time spent on SM, active SMU, and passive SMU. This umbrella review explains why their results disagree, summarizes the gaps in the literature, and ends with recommendations for future research.},
  langid = {english},
  keywords = {Depression,Facebook,Idiographic approach,Instagram,Mental health,Meta-analysis,Problematic social media use,Review,Social comparison,Social media,Well-being}
}


